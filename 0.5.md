---
layout: default
title: 0.5
version: 0.5.2
agent_version: 0.5.3
---

**Spline** (from **Sp**ark **line**age) project helps people get insight into data processing performed by **Apache Spark &trade;**

The project consists of three main parts:
- Spark Agent that sits on drivers, capturing the data lineage from Spark jobs being executed by analyzing the execution plans

-   Rest Gateway, that receive the lineage data from agent and stores it in the database

-   Web UI application that visualizes the stored data lineages

![Spline diagram](https://user-images.githubusercontent.com/5530211/70050339-fd93f580-15ce-11ea-88b2-4d79ee30d494.png)


There are several other tools. Check the examples to get a better idea how to use Spline.

Other docs/readme files can be found at:
  - [ClientUI](https://github.com/AbsaOSS/spline/tree/release/{{page.version}}/client-ui)
  - [Examples](https://github.com/AbsaOSS/spline-spark-agent/tree/release/{{page.agent_version}}/examples)
  - [Spark Agent](https://github.com/AbsaOSS/spline-spark-agent/tree/release/{{page.agent_version}})
  - [Spline Paper](https://github.com/AbsaOSS/spline/releases/download/release%2F0.2.7/Spline_paper_IEEE_2018.pdf)

Spline is aimed to be used with Spark 2.3+ but also provides limited support for Spark 2.2.

# Motivation

Spline aims to fill a big gap within the Apache Hadoop ecosystem. Spark jobs shouldnâ€™t be treated only as magic black boxes; people should be able to understand what happens with their data. Our main focus is to solve the following particular problems:

-   Regulatory requirement for SA banks (BCBS 239)

    By 2020, all South African banks will have to be able to prove how numbers are calculated in their reports to the regulatory authority.

-   Documentation of business logic

    Business analysts should get a chance to verify whether Spark jobs were written according to the rules they provided. Moreover, it would be beneficial for them to have up-to-date documentation where they can refresh their knowledge of a project.

-   Identification of performance bottlenecks

    Our focus is not only business-oriented; we also see Spline as a development tool that should be able to help developers with the performance optimization of their Spark jobs.

---

# Getting started

## TL;DR
If you have a Docker you can just download [docker-compose.yml](https://raw.githubusercontent.com/AbsaOSS/spline/release/{{page.title}}/docker-compose.yml) file,
run `docker-compose up` and you are all set for the demo.

```shell
wget https://raw.githubusercontent.com/AbsaOSS/spline/release/{{page.title}}/docker-compose.yml
docker-compose up
```

Run you Spark-shell or PySpark as below to enable lineage tracking:\
_(NOTE: we use Spline Agent bundle compiled for Spark 2.4 and Scala 2.12. For other Spark or Scala versions use corresponding bundles)_
   
```shell
pyspark \
  --packages za.co.absa.spline.agent.spark:spark-2.4-spline-agent-bundle_2.12:{{page.agent_version}} \
  --conf "spark.sql.queryExecutionListeners=za.co.absa.spline.harvester.listener.SplineQueryExecutionListener" \
  --conf "spark.spline.producer.url=http://localhost:9090/producer"
```

Execute any of your Spark Job that writes to a persistent storage (like file, Hive table or a database).
The lineage should be captured automatically.

Open [http://localhost:8080](http://localhost:8080) in your browser to see the captured lineage.

## Doing it step-by-step
First, you need to get a minimal set of Spline's moving parts - 
a server, an admin tool and a client Web UI to see the captured lineage.

There are two ways how to do it:

#### Download prebuild Spline artifacts from the Maven repo
-   [```za.co.absa.spline:admin:{{page.version}}```](https://repo1.maven.org/maven2/za/co/absa/spline/admin/{{page.version}}/)

-   [```za.co.absa.spline:rest-gateway:{{page.version}}```](https://repo1.maven.org/maven2/za/co/absa/spline/rest-gateway/{{page.version}}/) 

-   [```za.co.absa.spline:client-web:{{page.version}}```](https://repo1.maven.org/maven2/za/co/absa/spline/client-web/{{page.version}}/) (optional)

(REST Server and Web Client modules are also available as [Docker containers](https://hub.docker.com/u/absaoss))

-or-

#### Build Spline from the source code
**Note:** Skip this section unless you want to hack with Spline

1.  Make sure you have JDK 8, Maven and NodeJS installed.

2.  Get and unzip the Spline source code:
    ```shell
    wget https://github.com/AbsaOSS/spline/archive/release/{{page.version}}.zip
    unzip {{page.version}}.zip
    ```

3.  Change the directory:
    ```shell
    cd spline-release-{{page.version}}
    ```

4.  Run the Maven build:
    ```shell
    mvn install -DskipTests
    ```

## Create Spline Database
Spline server requires *ArangoDB* to run.

Please install _ArangoDB 3.5+_ according to the instructions in [ArangoDB documentation](https://www.arangodb.com/docs/stable/getting-started-installation.html).

Or if you prefer the Docker way there is a [ArangoDB docker image](https://hub.docker.com/_/arangodb/) as well.
```shell
docker pull arangodb:3.5.1
```

Either way once your database is running you should be able to see ArangoDB web interface at [http://localhost:8529](http://localhost:8529).

Next you need to create the spline database tables, views and so on. You can do it using admin tool that you downloaded from the maven (or build from the sources).

```shell
java -jar admin-{{page.version}}.jar db-init arangodb://localhost/spline
```

Check that the databse is initialized in the web interface [http://localhost:8529/_db/spline/](http://localhost:8529/_db/spline/).

## Start Spline Server
Spline server can be started using 2 different ways:

##### Docker
```shell
docker container run \
  -e spline.database.connectionUrl=arangodb://host.docker.internal/spline \
  -p 8080:8080 \
  absaoss/spline-rest-server:{{page.version}}
```
**Note for Linux**: If `host.docker.internal` does not resolve replace it with `172.17.0.1` (see [Docker for-linux bug report](https://github.com/docker/for-linux/issues/264))

##### Java compatible Web-Container (e.g. Tomcat)
You can find a WAR-file in the Maven repo here:

[`za.co.absa.spline:rest-gateway:{{page.version}}`](https://repo1.maven.org/maven2/za/co/absa/spline/rest-gateway/{{page.version}}/)

Add the argument for the ArangoDB connection string
```
-Dspline.database.connectionUrl=arangodb://localhost/spline
```

#### Verify Spline Server

Open the server root URL in you browser:
http://localhost:8080/

You should see a dashboard with the updating server status information, server version, exposed API and some other useful info. 


The server exposes the following REST API:
  - Producer API (`/producer/*`) 
  - Consumer API (`/consumer/*`)

... and other useful URLs:
  - Running server version information: [/about/version](http://localhost:8080/about/version)
  - Producer API Swagger documentation: [/docs/producer.html](http://localhost:8080/docs/producer.html) 
  - Consumer API Swagger documentation: [/docs/consumer.html](http://localhost:8080/docs/consumer.html) 

## Start Spline UI

Spline web client can be started using 3 different ways:

##### Docker
```shell
docker container run \
      -e spline.consumer.url=http://localhost:8080/consumer \
      -p 9090:8080 \
      absaoss/spline-web-client:{{page.version}}
```

##### Java compatible Web-Container (e.g. Tomcat)

You can find the WAR-file of the Web Client in the repo here:

[```za.co.absa.spline:client-web:{{page.version}}```](https://repo1.maven.org/maven2/za/co/absa/spline/client-web/{{page.version}}/)

Add the argument for the consumer url

```
-Dspline.consumer.url=http://localhost:8080/consumer
```

##### Node JS application (For development purposes)

Download [```node.js```](https://nodejs.org/en/) then install [```@angular/cli```](https://www.npmjs.com/package/@angular/cli) to run `ng serve` or `ng-build` command.

To specify the consumer url please edit the [config.json](https://github.com/AbsaOSS/spline/blob/release/{{page.version}}/client-ui/src/assets/config.json) file

You can find the documentation of this module in [ClientUI](https://github.com/AbsaOSS/spline/tree/release/{{page.version}}/client-ui).

### Check the result in the browser
<http://localhost:9090>

## Use spline in your application
Add a dependency on Spark Agent.
```xml
<dependency>
    <groupId>za.co.absa.spline.agent.spark</groupId>
    <artifactId>agent-core</artifactId>
    <version>{{page.agent_version}}</version>
</dependency>
```
In your spark job you have to enable spline.
```scala
// given a Spark session ...
val sparkSession: SparkSession = ???

// ... enable data lineage tracking with Spline
import za.co.absa.spline.harvester.SparkLineageInitializer._
sparkSession.enableLineageTracking()

// ... then run some Dataset computations as usual.
// Data lineage of the job will be captured and stored in the
// configured database for further visualization by Spline Web UI
```
### Properties

You also need to set some configuration properties. Spline combine these properties from several sources:
1.  Hadoop config (`core-site.xml`)

2.  JVM system properties

3.  `spline.properties` file in the classpath

#### `spline.mode`
-   *`DISABLED`* Lineage tracking is completely disabled and Spline is unhooked from Spark.

-   *`REQUIRED`* If Spline fails to initialize itself (e.g. wrong configuration, no db connection etc) the Spark application aborts with an error.

-   *`BEST_EFFORT`* (default) Spline will try to initialize itself, but if fails it switches to DISABLED mode allowing the Spark application to proceed normally without Lineage tracking.

#### `spline.producer.url`
-   url of spline producer (part of rest gateway responsible for storing lineages in database)

Example:
```properties
spline.mode=REQUIRED
spline.producer.url=http://localhost:8080/producer
```

# Upgrade from Spline 0.5 to 0.5.2

Although the version 0.5.2 being a bugfix release is fully compatible
with the other 0.5.x versions, there was a little change in an AQL function
that removes limitation on the maximum depth of the high level lineage overview graph.
Before version 0.5.2 only 10 jobs in the pipeline could be displayed on UI
(as a prevention for too slow query performance in case of deep and complex pipelines).
In Spline 0.5.2 the default threshold is still 10 jobs in a row, but the user would be prompted
to increase this limit if reached.    
To enable this feature run the `db-upgrade` command (see below),
or replace [`SPLINE::EVENT_LINEAGE_OVERVIEW`](https://github.com/AbsaOSS/spline/blob/release/0.5.2/persistence/src/main/resources/AQLFunctions/event_lineage_overview.js) function in ArangoDB manually if you don't want to rebuild existing indices.    

# Upgrade from Spline 0.4 to 0.5

There are some additions to Spline database in version 0.5 therefore you have to upgrade it. 
This is done by the same tool that is used for database creation, but this time call it with `db-upgrade` parameter.
The upgrade shouldn't change any data in the db it just deletes and creates views, functions and indicies.

```shell
java -jar admin-{{page.version}}.jar db-upgrade arangodb://localhost/spline
```

# Upgrade from Spline 0.3 to 0.4

Spline 0.3 was using MongoDB as a database. In Spline 0.4 we switched to ArangoDB.
Since using MongoDB as database is no longer supported you may need to migrate your data from MongoDB to ArangoDB. To do that, Simply run:
```shell 
java -jar migrator-tool/target/migrator-tool.jar \
  --source=mongodb://localhost:27017/splinedb \
  --target=http://localhost:8080/spline/producer
```

For more information you may take a look at [migrator tool source code](https://github.com/AbsaOSS/spline/tree/release/0.4/migrator-tool).

---

    Copyright 2019 ABSA Group Limited
    
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
    
        http://www.apache.org/licenses/LICENSE-2.0
    
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
